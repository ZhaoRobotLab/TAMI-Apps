**Project Descriptions**


PepperApp

This app contains a series of simple games for the Pepper robot:

·         Trivia: The robot selects 5 random trivia questions about the University of Tennessee from a list of 20 and displays them one at a time on her tablet. The user picks an answer, and the robot responds with “right” or “wrong”, highlighting the correct answer. The user then receives their score at the end.

·         Dancing: The robot displays a list of songs for the user to choose from. Once selected, the robot begins to play the song and dance to the rhythm.

·         Selfie: The robot does one of 5 preprogrammed poses at random. It then holds that pose for 30 seconds, allowing a user to take a picture of or with the robot. It also displays the University of Tennessee logo on the tablet screen during the pause.

·         Memory Match: The robot displays a grid of cards on the tablet screen. The user and the robot take turns flipping over two cards attempting to make a match. If a match is made, that player goes again. The player with the most matches once all cards have been flipped is the winner. During the activity, the robot makes encouraging remarks to the user.



MUSE

This app, named the Music intervention Using Socially Engaging robotics (MUSE), seeks to combine music intervention and social robotics, specifically for people with dementia. The robot guides users through a three-step music intervention session:

1.      Keep with the Rhythm: The robot displays a simple metronome and encourages users to tap along with the beat. It beats at 75, 95, and 115 BPM, lingering on each one for one minute before moving on to the next.

2.      Sing Along: The users first pick a music genre (as of now only 2 are implemented). Then, the robot begins to play a song from that genre while displaying the lyrics on screen. The users are encouraged to sing along to the song or tap to the metronome in the bottom right corner. The robot remains still during this activity to keep the tablet steady.

3.      Dance Along: The robot begins playing another song from the chosen genre, but this time it moves its upper body and dances to the music. The users are told to remain sitting but still dance to the music being played.



RISE

This app is designed for informal caregivers of people with dementia. The app is designed to give users a session and provide information on any issues they may be having in their caregiving journey. The app uses retrieval augmented generative AI (RAG-AI) to generate the sessions based on the Risk Assessment portion. The RAG-AI’s knowledge base is a 300-page caregiver notebook that was provided to us by our collaborators and covers 48 different topics in dementia caregiving. The RISE session is composed of the following sections:

1.      Risk Assessment: A list of yes or no questions on various issues an informal caregiver might be having. Based on the answers, the robot may recommend a specific module. The user can then choose one of the 48 topics for the Knowledge Module.

2.      Knowledge Module: Based on the selected topic, the robot guides the user through a 3-step information session

a.       Presentation: The RAG-AI generates slides based on the selected topic. The slides are based on the specified section in the caregiver notebook that the user chose and provides a general overview of the information from that section. The slides are shown on the tablet screen while the robot narrates them.

b.      Q&A: The user has the chance to ask the AI any lingering questions they may have. They can type or speak their questions into the tablet, which displays a standard chat interface. The AI then generates an answer to the question based on the information from the caregiver notebook. If the question cannot be answered by the notebook, the robot then refers the user to a professional.

c.       Review Quiz: The AI generates 5 multiple choice questions based on the information presented in the presentation. The robot then displays and narrates each question one at a time. Once the user selects an answer, the robot either confirms it, or it highlights the correct answer if they are wrong. At the end, the robot displays the score and allows the user to retake the quiz.

After they complete the Review Quiz, the user can then decide to either do another Knowledge Module or continue on to the Stress Management Activity.

3.      Stress Management: The user selects one of the stress management activities displayed on the screen. The robot then guides the user through the activity and encourages them to participate. After they are done, the user can move on, and the robot will thank them for participating in a RISE session. The session then ends there.



GRA

The GRA is designed to support individuals at risk for hereditary cancer by guiding them through an educational genetic risk assessment (GRA) session. The app uses a combination of a humanoid social robot (Pepper) and retrieval-augmented generative AI (RAG-AI) to deliver personalized and trustworthy cancer-related information. The RAG-AI’s knowledge base consists of certified materials provided by medical experts, including resources from the National Comprehensive Cancer Network and the National Society of Genetic Counselors. The GRA session is composed of the following sections:

1.      AI-Generated Presentation: A brief educational overview introducing the user to genetic testing and their specific cancer diagnosis. The content is generated using RAG-AI and displayed on Pepper’s tablet. The robot narrates each slide with gestures and eye contact to enhance engagement. Users can control slide navigation using the tablet interface. Generic images are used for visual support, and future versions may include AI-generated diagrams.

2.      AI-Powered Q&A: Users can ask follow-up questions through a chat-style interface. They may type their questions or speak using the robot’s microphone. RAG-AI generates answers exclusively from the vetted knowledge base to ensure accuracy. If a question cannot be answered from the embedded materials, the robot advises the user to consult a professional. The robot speaks responses aloud and uses social gestures to maintain a conversational tone.

3.      AI-Enabled Knowledge Quiz: To reinforce learning, the app presents five multiple-choice questions based on the earlier presentation. RAG-AI generates the correct answer, while GPT-4 provides plausible but incorrect alternatives to ensure balanced difficulty. The quiz helps confirm user comprehension, and users can revisit previous sections if needed for review.

The GRA app currently focuses on colon cancer but is designed to be scalable to other cancer types. Future updates aim to integrate personalized inputs such as family history and lifestyle, expand content scope, and improve accessibility features like speech recognition. Sessions with the robot aim to make genetic education more engaging and accessible, supporting informed decision-making in healthcare.
